{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from pprint import pprint\n",
    "\n",
    "from jieba_postag_converter import get_postag_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def calc_tfidf(data):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    x = tfidf.fit_transform(data)\n",
    "    df_tfidf = pd.DataFrame(x.toarray(), columns=tfidf.get_feature_names())\n",
    "    return df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_words_by_unalighed_diff_counts(df,corpus='cejc',situation='apology',sen_type='query', diff_type='del', reverse=False, tfidf=False):\n",
    "    # FOR creating words ranking graph and pos rangling graph\n",
    "#     cols = {'primitive form':'word count', 'pos':'pos count'}\n",
    "    df = df[(df['corpus']==corpus)&(df['situation']==situation)&(df['sentence type']==sen_type)&(df['difference type']==diff_type)]\n",
    "      \n",
    "    cols = {'primitive form':'word count'}\n",
    "    for label_col, data_col in cols.items():\n",
    "        if tfidf == True:\n",
    "            df = df.assign(tfidf = list(np.zeros(len(df))))\n",
    "            dirs = ['/nfs/nas-7.1/yamashita/LAB/giza-pp/primitive']\n",
    "            corpora = ['cejc']\n",
    "            situations = ['apology']\n",
    "            method_type = ['rewrited']\n",
    "            sentence_type = ['query']\n",
    "            data = []\n",
    "            for d in dirs:\n",
    "                for c in corpora:\n",
    "                    for s in situations:\n",
    "                        for m in method_type:\n",
    "                            if m != 'original':\n",
    "                                c = 'mpdd' if corpus == 'cejc' else 'mpdd'\n",
    "                            for t in sentence_type:\n",
    "                                path =f'{d}/{c}/{s}/{m}_{t}'\n",
    "                                with open(path, 'r', encoding='utf_8_sig')as f:\n",
    "                                    for i,sen in enumerate(f):\n",
    "                                        line = sen[:-1]\n",
    "                                        data.append(line)\n",
    "            tfidf_df=calc_tfidf(data)\n",
    "            for index, row in df.iterrows():\n",
    "                line= row['line']\n",
    "                prim= row['primitive form']\n",
    "                try:\n",
    "                    df.loc[index, 'tfidf'] = tfidf_df.loc[line, prim]\n",
    "                except:\n",
    "#                     print(prim)\n",
    "                        pass\n",
    "                \n",
    "            df[data_col] = df.groupby(['corpus', 'situation', 'method', 'sentence type', 'difference type',label_col])['tfidf'].transform(np.sum)\n",
    "        else:\n",
    "            df[data_col] = df.groupby(['corpus', 'situation', 'method', 'sentence type', 'difference type',label_col])['index'].transform('count')\n",
    "        \n",
    "        df_word = df.drop_duplicates(['corpus', 'situation', 'method', 'sentence type', 'difference type',label_col]).sort_values(by=data_col, ascending=False)\n",
    "        df_word = df_word.dropna(subset=[label_col])\n",
    "\n",
    "        # GET data for 1 graph\n",
    "#         difference_type = ['del','add']\n",
    "        method_type = ['translated','rewrited']\n",
    "        data, labels = [], []\n",
    "        _temp_w, _temp_wv = [], [] \n",
    "        for method in method_type:\n",
    "            _temp_w.append(df_word[df_word['method']==method][label_col])\n",
    "            _temp_wv.append(df_word[df_word['method']==method][data_col])\n",
    "        # PUT data into dictionary, COUNT freq., CALCULATE (rewrited - translated) and SORT them\n",
    "        dic = {}\n",
    "        for i,(wline,vline) in enumerate(zip(_temp_w,_temp_wv)):\n",
    "            for j,(w,v) in enumerate(zip(wline,vline)):\n",
    "                if w in dic:\n",
    "                    dic[w]['each'][i]=v\n",
    "                    v = v*-1 if i==0 else v\n",
    "                    dic[w]['diff']=dic.get(w,dic.get('diff',0))['diff']+v\n",
    "                else:\n",
    "                    tmp = [0,0]\n",
    "                    tmp[i] = v\n",
    "                    v = v*-1 if i==0 else v\n",
    "                    dic.setdefault(w,{'each':tmp,'diff':v})\n",
    "        dic = sorted(dic.items(),key=lambda x:x[1]['diff'],reverse=reverse)\n",
    "#         pprint(dic)\n",
    "        # exit()\n",
    "#         data_w, data_wv = [],[[],[]]\n",
    "#         for key, values in dic:\n",
    "#             data_w.append(key)\n",
    "#             data_wv[0].append(values['each'][0])\n",
    "#             data_wv[1].append(values['each'][1]) \n",
    "        data_w, data_wv = [],[]\n",
    "        for key, values in dic:\n",
    "            data_w.append(key)\n",
    "            data_wv.append(values['diff'])\n",
    "        labels.append(data_w)\n",
    "        data.append(data_wv)\n",
    "        df_ = pd.DataFrame([data_w,data_wv]).T.set_axis(['word','diff count'],axis='columns')\n",
    "        print(df_)\n",
    "        return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prim2mrph(df,df_,corpus,situation,sen_type,diff_type,mincnt):\n",
    "    ranked_words_list = df_[df_['diff count'] >= mincnt]['word'].to_list()\n",
    "#     print(ranked_words_list)\n",
    "#     print(len(ranked_words_list))\n",
    "    df = df[df[\"corpus\"].isin([corpus])&\\\n",
    "            df['situation'].isin([situation])&\\\n",
    "            df[\"difference type\"].isin([diff_type])&\\\n",
    "            df[\"primitive form\"].isin(ranked_words_list)&\\\n",
    "            df['sentence type'].isin([sen_type])]['word']\n",
    "    word_list = df.to_list()\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highdiff_mrphwords(df,corpus,situation,sen_type,diff_type,mincnt,reverse,tfidf):\n",
    "    if diff_type=='add':\n",
    "        corpus = 'mpdd' if corpus == 'cejc' else 'cejc'\n",
    "    df_ = rank_words_by_unalighed_diff_counts(df,corpus,situation,sen_type,diff_type,reverse,tfidf)\n",
    "    word_list = prim2mrph(df,df_,corpus,situation,sen_type,diff_type,mincnt)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_path = \"analysis_table.csv\"\n",
    "df = pd.read_csv(t_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word diff count\n",
      "0       ああ        -48\n",
      "1       ます        -29\n",
      "2       いる        -23\n",
      "3        ぬ        -20\n",
      "4       する        -18\n",
      "..     ...        ...\n",
      "260      お          4\n",
      "261     もう          4\n",
      "262     お前          5\n",
      "263  すみません          5\n",
      "264  申し訳ない          6\n",
      "\n",
      "[265 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['お前',\n",
       " 'ご',\n",
       " '家',\n",
       " '用事',\n",
       " '遅れて',\n",
       " '校長',\n",
       " '本当に',\n",
       " 'お',\n",
       " 'ちゃんと',\n",
       " '申請',\n",
       " '休んで',\n",
       " '本当に',\n",
       " 'もう',\n",
       " '江',\n",
       " 'お',\n",
       " 'た',\n",
       " 'お前',\n",
       " '本当に',\n",
       " 'すみません',\n",
       " 'お',\n",
       " 'あいつ',\n",
       " 'すみません',\n",
       " '外',\n",
       " '方',\n",
       " '農村',\n",
       " 'すみません',\n",
       " 'お',\n",
       " 'お',\n",
       " 'ごめんなさい',\n",
       " '出身',\n",
       " 'すみません',\n",
       " 'ごめんなさい',\n",
       " 'お前',\n",
       " 'ご',\n",
       " '申し訳ない',\n",
       " '本当に',\n",
       " '申し訳ない',\n",
       " '絶対',\n",
       " 'お前',\n",
       " '申し訳ない',\n",
       " '大事な',\n",
       " '愛',\n",
       " '申し訳ない',\n",
       " 'ごめんなさい',\n",
       " 'ごめん',\n",
       " '今',\n",
       " '子供',\n",
       " 'ごめんなさい',\n",
       " '弱って',\n",
       " 'る',\n",
       " '初めて',\n",
       " '強',\n",
       " '方',\n",
       " '子だから',\n",
       " '大事な',\n",
       " '他の',\n",
       " 'つながり',\n",
       " '遅れた',\n",
       " '文',\n",
       " 'もう',\n",
       " 'もう',\n",
       " 'れて',\n",
       " 'る',\n",
       " 'た',\n",
       " 'いいん',\n",
       " '今日',\n",
       " '市',\n",
       " '名',\n",
       " '家',\n",
       " 'どうしても',\n",
       " '立て',\n",
       " '会った',\n",
       " 'もらう',\n",
       " 'れて',\n",
       " 'もう',\n",
       " '元',\n",
       " '補償',\n",
       " 'まずい',\n",
       " '申し訳ない',\n",
       " '考えて',\n",
       " 'た',\n",
       " 'た',\n",
       " '不安に',\n",
       " 'もう',\n",
       " 'る',\n",
       " '兄さん',\n",
       " '傷つける',\n",
       " 'お',\n",
       " '兄さん',\n",
       " '一',\n",
       " 'お前',\n",
       " '申し訳ない',\n",
       " 'ありがとう',\n",
       " 'ください',\n",
       " '今',\n",
       " 'ちゃんと',\n",
       " 'すみません',\n",
       " 'ごめんなさい',\n",
       " '方',\n",
       " 'た',\n",
       " 'そういう',\n",
       " 'ごめんなさい',\n",
       " 'あげ',\n",
       " 'とき',\n",
       " 'ただ',\n",
       " 'お',\n",
       " '義姉',\n",
       " 'せて',\n",
       " 'る',\n",
       " '不安に',\n",
       " '悪い',\n",
       " '意味',\n",
       " 'お',\n",
       " 'ください',\n",
       " '元',\n",
       " '社',\n",
       " '主要な',\n",
       " '事件',\n",
       " '一',\n",
       " 'ください',\n",
       " '申し訳ない',\n",
       " 'あげ',\n",
       " 'る',\n",
       " 'ごめんなさい',\n",
       " 'いろんな',\n",
       " 'ともかく',\n",
       " 'お',\n",
       " 'ごめん',\n",
       " '遅れて',\n",
       " 'ください',\n",
       " '本当に',\n",
       " 'ごめんなさい',\n",
       " 'る',\n",
       " 'お',\n",
       " '今',\n",
       " 'ごめんなさい',\n",
       " 'あげ',\n",
       " 'お',\n",
       " 'た',\n",
       " 'お',\n",
       " '申し訳ない',\n",
       " 'お',\n",
       " 'る',\n",
       " 'れて',\n",
       " 'る',\n",
       " 'ごめんなさい',\n",
       " 'ごめんなさい',\n",
       " 'もう',\n",
       " '兄さん',\n",
       " 'る',\n",
       " '本当に',\n",
       " '本当に',\n",
       " 'ごめんなさい',\n",
       " '書き',\n",
       " 'は',\n",
       " 'る',\n",
       " '家',\n",
       " 'る',\n",
       " '一',\n",
       " 'お',\n",
       " 'る']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = 'cejc'\n",
    "situation = 'apology'\n",
    "sen_type = 'query'\n",
    "diff_type = 'add'\n",
    "mincnt = 1\n",
    "\n",
    "word_list = get_highdiff_mrphwords(df,corpus,situation,sen_type,diff_type,mincnt,reverse=False,tfidf=False)\n",
    "word_list\n",
    "# len(word_list)\n",
    "# df_[df_['diff count'] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ああ</th>\n",
       "      <th>あう</th>\n",
       "      <th>あげる</th>\n",
       "      <th>あご</th>\n",
       "      <th>あす</th>\n",
       "      <th>あたし</th>\n",
       "      <th>あっ</th>\n",
       "      <th>あと</th>\n",
       "      <th>あなた</th>\n",
       "      <th>あの</th>\n",
       "      <th>...</th>\n",
       "      <th>順番</th>\n",
       "      <th>頼む</th>\n",
       "      <th>願う</th>\n",
       "      <th>食べる</th>\n",
       "      <th>食事</th>\n",
       "      <th>飲み物</th>\n",
       "      <th>飽きる</th>\n",
       "      <th>駄目だ</th>\n",
       "      <th>黒豆</th>\n",
       "      <th>ｐｄｆ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>419 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ああ   あう  あげる   あご   あす       あたし        あっ        あと  あなた        あの  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.268836  0.000000  0.000000  0.0  0.253486   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "..   ...  ...  ...  ...  ...       ...       ...       ...  ...       ...   \n",
       "414  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.373143  0.0  0.000000   \n",
       "415  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.594443  0.0  0.000000   \n",
       "416  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "417  0.0  0.0  0.0  0.0  0.0  0.000000  0.499285  0.000000  0.0  0.000000   \n",
       "418  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "     ...   順番   頼む        願う  食べる   食事  飲み物  飽きる  駄目だ   黒豆  ｐｄｆ  \n",
       "0    ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2    ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4    ...  0.0  0.0  0.366714  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...       ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "414  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "415  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "416  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "417  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "418  ...  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[419 rows x 610 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    dirs = ['/nfs/nas-7.1/yamashita/LAB/giza-pp/primitive']\n",
    "    corpora = ['cejc','mpdd']\n",
    "    situations = ['apology','request','thanksgiving']\n",
    "    method_type = ['original','translated','rewrited']\n",
    "    sentence_type = ['query', 'res']\n",
    "    corpora = ['cejc']\n",
    "    situations = ['apology']\n",
    "    method_type = ['original']\n",
    "    sentence_type = ['query']\n",
    "    data = []\n",
    "    for d in dirs:\n",
    "        for corpus in corpora:\n",
    "            for situation in situations:\n",
    "                for m in method_type:\n",
    "                    for t in sentence_type:\n",
    "                        path =f'{d}/{corpus}/{situation}/{m}_{t}'\n",
    "                        with open(path, 'r', encoding='utf_8_sig')as f:\n",
    "                            for i,sen in enumerate(f):\n",
    "                                line = sen[:-1]\n",
    "                                data.append(line)\n",
    "tfidf_df=calc_tfidf(data)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word diff count\n",
      "0     のだ          0\n",
      "1      ぬ          0\n",
      "2     いい          0\n",
      "3     じゃ          0\n",
      "4    土曜日          0\n",
      "..   ...        ...\n",
      "215   一応          0\n",
      "216   石井          0\n",
      "217   ない -0.0137169\n",
      "218   する  -0.044278\n",
      "219  ごめん  -0.146287\n",
      "\n",
      "[220 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_path = \"analysis_table.csv\"\n",
    "df = pd.read_csv(t_path)\n",
    "\n",
    "corpus = 'cejc'\n",
    "situation = 'apology'\n",
    "sen_type = 'query'\n",
    "diff_type = 'del'\n",
    "mincnt = 1\n",
    "\n",
    "word_list = get_highdiff_mrphwords(df,corpus,situation,sen_type,diff_type,mincnt,reverse=True,tfidf=True)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
