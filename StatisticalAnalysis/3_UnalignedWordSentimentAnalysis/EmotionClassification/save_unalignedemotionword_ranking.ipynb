{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib as plt\n",
    "import matplotlib.style\n",
    "import itertools\n",
    "from collections import Counter\n",
    "jiwc = {}\n",
    "files_path = [  '../sentiment_analysis/JIWC_Dictionary/ver_2018/JIWC-C_2018.csv',\n",
    "                '../sentiment_analysis/JIWC_Dictionary/ver_2019/JIWC-C_2019.csv',\n",
    "                '../sentiment_analysis/JIWC_Dictionary/JIWC-C_2018_2019.csv']\n",
    "for path in files_path:\n",
    "    with open(path,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i,row in enumerate(reader): \n",
    "            if i == 0 :\n",
    "                continue\n",
    "            jiwc.setdefault(row[0],'Sadness')\n",
    "            jiwc.setdefault(row[1],'Anxiety')\n",
    "            jiwc.setdefault(row[2],'Anger')\n",
    "            jiwc.setdefault(row[3],'Disgust')\n",
    "            jiwc.setdefault(row[4],'Trust')\n",
    "            jiwc.setdefault(row[5],'Surprise')\n",
    "            jiwc.setdefault(row[6],'Joy')\n",
    "# pprint(jiwc)\n",
    "\n",
    "def extract_words_by_emotion(unaligned, emotion, stop_words):\n",
    "    emo_words = []\n",
    "    for i , sen in enumerate(unaligned):\n",
    "        tmp = []\n",
    "        for j, w in enumerate(sen):\n",
    "            if w not in stop_words:\n",
    "                if w in jiwc:\n",
    "                    if jiwc[w]==emotion:\n",
    "                        tmp.append(w)\n",
    "        emo_words.append(tmp)\n",
    "    return emo_words\n",
    "\n",
    "def get_data_as_list(fpath) -> list:\n",
    "    data = []\n",
    "    with open(fpath, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\",\"\").split(\" \")\n",
    "            data.append(line)\n",
    "    return data\n",
    "\n",
    "def get_unaligned_mrphwords(unaligned_index,mrph):\n",
    "    unaligned_mrphwords = []\n",
    "    for i, index in enumerate(unaligned_index):\n",
    "        tmp = []\n",
    "        for indice in index:\n",
    "            if indice == \"\":\n",
    "                continue\n",
    "            try:\n",
    "                tmp.append(mrph[int(i)][int(indice)])\n",
    "            except:\n",
    "                print('index: ',index)\n",
    "                print('indice: ',indice)\n",
    "                print('len(mrph[int(i)]): ',len(mrph[int(i)]))\n",
    "                print(mrph[int(i)])\n",
    "        unaligned_mrphwords.append(tmp)\n",
    "    return unaligned_mrphwords\n",
    "\n",
    "\n",
    "def get_ranking(corpus,situation,sen_type,emotion,diff_type):\n",
    "    stop_words=[\"の\",\"に\",\"こと\",\"\",\"\"]\n",
    "    \n",
    "    method = 'rewrited'\n",
    "\n",
    "    unaligned_index_fpath= '../analysis/unaligned_index/' + f\"{corpus}/{situation}/{method}_{sen_type}.{diff_type}\"\n",
    "    ref_method='original' if diff_type=='del' else method\n",
    "    mrph_fpath= '../mrphdata/'+ f\"{corpus}/{situation}/{ref_method}_{sen_type}\"\n",
    "    unaligned_index = get_data_as_list(unaligned_index_fpath)\n",
    "    rewrited_mrph = get_data_as_list(mrph_fpath)\n",
    "    rewrited_unaligned = get_unaligned_mrphwords(unaligned_index,rewrited_mrph)\n",
    "\n",
    "\n",
    "    method = 'translated'  \n",
    "\n",
    "    unaligned_index_fpath= '../analysis/unaligned_index/' + f\"{corpus}/{situation}/{method}_{sen_type}.{diff_type}\"\n",
    "    ref_method='original' if diff_type=='del' else method\n",
    "    mrph_fpath= '../mrphdata/'+ f\"{corpus}/{situation}/{ref_method}_{sen_type}\"\n",
    "    unaligned_index = get_data_as_list(unaligned_index_fpath)\n",
    "    translated_mrph = get_data_as_list(mrph_fpath)\n",
    "    translated_unaligned = get_unaligned_mrphwords(unaligned_index,translated_mrph)\n",
    "\n",
    "    translated_emo_words = extract_words_by_emotion(translated_unaligned,emotion,stop_words)\n",
    "    # translated_emo_words\n",
    "    rewrited_emo_words = extract_words_by_emotion(rewrited_unaligned,emotion,stop_words)\n",
    "    # rewrited_emo_words\n",
    "    \n",
    "    words = translated_emo_words\n",
    "    words = itertools.chain.from_iterable(words)\n",
    "    words = Counter(words)\n",
    "    words = words.most_common()\n",
    "    mt_words, mt_val = [],[]\n",
    "    for w,v in words:\n",
    "        mt_words.append(w)\n",
    "        mt_val.append(v)\n",
    "        \n",
    "    words = rewrited_emo_words\n",
    "    words = itertools.chain.from_iterable(words)\n",
    "    words = Counter(words)\n",
    "    words = words.most_common()\n",
    "    ht_words, ht_val = [],[]\n",
    "    for w,v in words:\n",
    "        ht_words.append(w)\n",
    "        ht_val.append(v)\n",
    "        \n",
    "    dic = {}\n",
    "    for w,v in (zip(ht_words, ht_val)):     \n",
    "        if w in dic:\n",
    "            dic[w]+=v\n",
    "        else:\n",
    "            dic.setdefault(w,v)\n",
    "    for w,v in (zip(mt_words, mt_val)):     \n",
    "        if w in dic:\n",
    "            v = v*-1 \n",
    "            dic[w]+=v\n",
    "        else:\n",
    "            v = v*-1\n",
    "            dic.setdefault(w,v)           \n",
    "    dic = sorted(dic.items(),key=lambda x:x[1],reverse=True)\n",
    "#     print(dic)\n",
    "    words, diff_val=[],[]\n",
    "    for key, values in dic:\n",
    "        words.append(key)\n",
    "        diff_val.append(values)\n",
    "\n",
    "    data = [mt_words, mt_val, ht_words, ht_val, words, diff_val]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|diff type|corpus|sen type|situation|emotion|\n",
    "|---|---|---|---|---|\n",
    "|del|cejc|query|apology||\n",
    "|del|cejc|query|request|Trust|\n",
    "|del|cejc|query|thanksgiving|Trust|\n",
    "|del|cejc|res|apology||\n",
    "|del|cejc|res|request|Trust|\n",
    "|del|cejc|res|thanksgiving||\n",
    "|add|mpdd|query|apology|Disgust|\n",
    "|add|mpdd|query|request|Sadness, Disgust, Joy|\n",
    "|add|mpdd|query|thanksgiving|Sadness, Disgust, Trust, Joy|\n",
    "|add|mpdd|res|apology||\n",
    "|add|mpdd|res|request|Sadness, Disgust, Trust, Joy|\n",
    "|add|mpdd|res|thanksgiving|Sadness|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_list=[   ['del','cejc','query','request','Trust'],\n",
    "                ['del','cejc','query','thanksgiving','Trust'],\n",
    "                ['del','cejc','res','request','Trust'],\n",
    "                ['add','mpdd','query','apology','Disgust'],\n",
    "                ['add','mpdd','query','request','Sadness'], \n",
    "                ['add','mpdd','query','request','Disgust'],\n",
    "                ['add','mpdd','query','request','Joy'],\n",
    "                ['add','mpdd','query','thanksgiving','Sadness'],\n",
    "                ['add','mpdd','query','thanksgiving','Disgust'],\n",
    "                ['add','mpdd','query','thanksgiving','Trust'], \n",
    "                ['add','mpdd','query','thanksgiving','Joy'],\n",
    "                ['add','mpdd','res','request','Sadness'],\n",
    "                ['add','mpdd','res','request','Disgust'],\n",
    "                ['add','mpdd','res','request','Trust'],\n",
    "                ['add','mpdd','res','request','Joy'],\n",
    "                ['add','mpdd','res','thanksgiving','Sadness']]\n",
    "# zh_sig_list=[   ['del',\t'mpdd',\t'query',\t'request',\t\t'affect'],\n",
    "#                 ['del',\t'mpdd',\t'query',\t'request',\t\t'negemo'],\n",
    "#                 ['del',\t'mpdd',\t'query',\t'request',\t\t'anger'],\n",
    "#                 ['del',\t'mpdd',\t'res',\t'thanksgiving',\t'affect'],\n",
    "#                 ['add',\t'cejc',\t'query',\t'apology',\t    'affect'],\n",
    "#                 ['add',\t'cejc',\t'query',\t'apology',\t    'posemo'],\n",
    "#                 ['add',\t'cejc',\t'query',\t'apology',\t    'negemo'],\n",
    "#                 ['add',\t'cejc',\t'query',\t'apology',\t    'anger'],\n",
    "#                 ['add',\t'cejc',\t'query',\t'request',\t    'negemo'],\n",
    "#                 ['add',\t'cejc',\t'res',\t'request',\t    'affect'],\n",
    "#                 ['add',\t'cejc',\t'res',\t'request',\t    'posemo']]\n",
    "# corpus,situation,sentence_type,count_type,unalignment_type,ranking\n",
    "###################################################################\n",
    "###################################################################\n",
    "data = []\n",
    "l_name = []\n",
    "c_name = []\n",
    "s_name = []\n",
    "t_name = []\n",
    "m_name = []\n",
    "d_name = []\n",
    "r_name = []\n",
    "e_name = []\n",
    "for s in sig_list:\n",
    "    unalignment_type=s[0]\n",
    "    corpus=s[1]\n",
    "    sentence_type=s[2]\n",
    "    situation=s[3]\n",
    "    emotion=s[4]\n",
    "\n",
    "    if unalignment_type == 'del':\n",
    "        if corpus == 'cejc':\n",
    "            language = 'ch'\n",
    "        else:\n",
    "            language = 'jp'\n",
    "    else:\n",
    "        if corpus == 'cejc':\n",
    "            language = 'jp'\n",
    "        else:\n",
    "            language = 'ch'\n",
    "\n",
    "    tmp=get_ranking(corpus,situation,sentence_type,emotion,unalignment_type)\n",
    "    for i in range(6):\n",
    "        l_name.append(f'{language}')\n",
    "        c_name.append(f'{corpus}')\n",
    "        s_name.append(f'{situation}')\n",
    "        t_name.append(f'{sentence_type}')\n",
    "        d_name.append(f'{unalignment_type}')\n",
    "        e_name.append(f'{emotion}')\n",
    "    m_name.extend(['MT','MT','HT','HT','Diff','Diff'])\n",
    "    r_name.extend(['word','freq','word','freq','word','freq'])\n",
    "    data.extend(tmp)\n",
    "    \n",
    "tuples = list(zip(l_name,c_name,s_name,t_name,m_name,d_name,e_name,r_name))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=[\"language\",\"corpus\", \"situation\",\"sentence_type\",\"count_type\",\"unalignment_type\",\"emotion\",\"ranking\",])\n",
    "table = pd.DataFrame(data,index=index)\n",
    "\n",
    "dir_name = 'for_thesis/LIWC_word_ranking/'\n",
    "os.makedirs(dir_name,exist_ok = True) \n",
    "table.to_csv(dir_name+'JIWC.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(dir_name+'JIWC.csv')\n",
    "# df = df[df['ranking'].str.contains('freq')]\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from inlp.convert import chinese\n",
    "import scipy.stats as stats\n",
    "import matplotlib as plt\n",
    "import matplotlib.style\n",
    "\n",
    "fpath = '../sentiment_analysis/CLIWC_Dictionary/cliwc2015 v1.4.3.dic'\n",
    "\n",
    "category_dict = {}\n",
    "cliwc = {}\n",
    "with open(fpath, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    for i,line in enumerate(f):\n",
    "        line = line.lstrip(\"\\t*\")\n",
    "        line = re.sub(r\"\\(.+\\)\",\"\",line)\n",
    "        line = line.rstrip()\n",
    "        line = line.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        if (i >= 1) and (i <= 79):\n",
    "            category_dict.setdefault(line[0],line[1])\n",
    "        if (i >= 81):\n",
    "            line[0] = chinese.t2s(line[0]) \n",
    "            cliwc.setdefault(line[0],line[1:])\n",
    "\n",
    "def extract_words_by_emotion_(unaligned, emotion, stop_words):\n",
    "    emo_words = []\n",
    "    for i , sen in enumerate(unaligned):\n",
    "        tmp = []\n",
    "        for j, w in enumerate(sen): \n",
    "            if w not in stop_words:\n",
    "                if w in cliwc:\n",
    "                    for key in cliwc[w]:\n",
    "                        if category_dict[key] == emotion:\n",
    "                            tmp.append(w)\n",
    "                # Bigram\n",
    "                if j>=1:\n",
    "                    w = sen[j-1]+sen[j]\n",
    "                    if w in cliwc:\n",
    "                        for key in cliwc[w]:\n",
    "                            if category_dict[key] == emotion:\n",
    "                                tmp.append(w)\n",
    "                # Trigram\n",
    "                if j>=2:\n",
    "                    w = sen[j-2]+sen[j-1]+sen[j]\n",
    "                    if w in cliwc:\n",
    "                        for key in cliwc[w]:\n",
    "                            if category_dict[key] == emotion:\n",
    "                                tmp.append(w)\n",
    "                # quadgram\n",
    "                if j>=3:\n",
    "                    w = sen[j-3]+sen[j-2]+sen[j-1]+sen[j]\n",
    "                    if w in cliwc:\n",
    "                        for key in cliwc[w]:\n",
    "                            if category_dict[key] == emotion:\n",
    "                                tmp.append(w)\n",
    "        emo_words.append(tmp)\n",
    "    return emo_words   \n",
    "\n",
    "def get_ranking_(corpus,situation,sen_type,emotion,diff_type):\n",
    "    stop_words=[]\n",
    "    \n",
    "    method = 'rewrited'\n",
    "\n",
    "    unaligned_index_fpath= '../analysis/unaligned_index/' + f\"{corpus}/{situation}/{method}_{sen_type}.{diff_type}\"\n",
    "    ref_method='original' if diff_type=='del' else method\n",
    "    mrph_fpath= '../mrphdata/'+ f\"{corpus}/{situation}/{ref_method}_{sen_type}\"\n",
    "    unaligned_index = get_data_as_list(unaligned_index_fpath)\n",
    "    rewrited_mrph = get_data_as_list(mrph_fpath)\n",
    "    rewrited_unaligned = get_unaligned_mrphwords(unaligned_index,rewrited_mrph)\n",
    "\n",
    "\n",
    "    method = 'translated'  \n",
    "\n",
    "    unaligned_index_fpath= '../analysis/unaligned_index/' + f\"{corpus}/{situation}/{method}_{sen_type}.{diff_type}\"\n",
    "    ref_method='original' if diff_type=='del' else method\n",
    "    mrph_fpath= '../mrphdata/'+ f\"{corpus}/{situation}/{ref_method}_{sen_type}\"\n",
    "    unaligned_index = get_data_as_list(unaligned_index_fpath)\n",
    "    translated_mrph = get_data_as_list(mrph_fpath)\n",
    "    translated_unaligned = get_unaligned_mrphwords(unaligned_index,translated_mrph)\n",
    "#     print(rewrited_mrph[:5])\n",
    "#     print(translated_mrph[:5])\n",
    "#     print(rewrited_unaligned[:5])\n",
    "#     print(translated_unaligned[:5])\n",
    "\n",
    "    translated_emo_words = extract_words_by_emotion_(translated_unaligned,emotion,stop_words)\n",
    "    rewrited_emo_words = extract_words_by_emotion_(rewrited_unaligned,emotion,stop_words)\n",
    "#     print(translated_emo_words[:5])\n",
    "    # rewrited_emo_words\n",
    "    # translated_emo_words\n",
    "    words = translated_emo_words\n",
    "    words = itertools.chain.from_iterable(words)\n",
    "    words = Counter(words)\n",
    "    words = words.most_common()\n",
    "    mt_words, mt_val = [],[]\n",
    "    for w,v in words:\n",
    "        mt_words.append(w)\n",
    "        mt_val.append(v)\n",
    "\n",
    "    words = rewrited_emo_words\n",
    "    words = itertools.chain.from_iterable(words)\n",
    "    words = Counter(words)\n",
    "    words = words.most_common()\n",
    "    ht_words, ht_val = [],[]\n",
    "    for w,v in words:\n",
    "        ht_words.append(w)\n",
    "        ht_val.append(v)\n",
    "\n",
    "    dic = {}\n",
    "    for w,v in (zip(ht_words, ht_val)):     \n",
    "        if w in dic:\n",
    "            dic[w]+=v\n",
    "        else:\n",
    "            dic.setdefault(w,v)\n",
    "    for w,v in (zip(mt_words, mt_val)):     \n",
    "        if w in dic:\n",
    "            v = v*-1 \n",
    "            dic[w]+=v\n",
    "        else:\n",
    "            v = v*-1\n",
    "            dic.setdefault(w,v)           \n",
    "    dic = sorted(dic.items(),key=lambda x:x[1],reverse=True)\n",
    "#     print(dic)\n",
    "    words, diff_val=[],[]\n",
    "    for key, values in dic:\n",
    "        words.append(key)\n",
    "        diff_val.append(values)\n",
    "\n",
    "    data = [mt_words, mt_val, ht_words, ht_val, words, diff_val]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sig_list=[   ['del','cejc','query','request','Trust'],\n",
    "#                 ['del','cejc','query','thanksgiving','Trust'],\n",
    "#                 ['del','cejc','res','request','Trust'],\n",
    "#                 ['add','mpdd','query','apology','Disgust'],\n",
    "#                 ['add','mpdd','query','request','Sadness'], \n",
    "#                 ['add','mpdd','query','request','Disgust'],\n",
    "#                 ['add','mpdd','query','request','Joy'],\n",
    "#                 ['add','mpdd','query','thanksgiving','Sadness'],\n",
    "#                 ['add','mpdd','query','thanksgiving','Disgust'],\n",
    "#                 ['add','mpdd','query','thanksgiving','Trust'], \n",
    "#                 ['add','mpdd','query','thanksgiving','Joy'],\n",
    "#                 ['add','mpdd','res','request','Sadness'],\n",
    "#                 ['add','mpdd','res','request','Disgust'],\n",
    "#                 ['add','mpdd','res','request','Trust'],\n",
    "#                 ['add','mpdd','res','request','Joy'],\n",
    "#                 ['add','mpdd','res','thanksgiving','Sadness']]\n",
    "sig_list=[   ['del',\t'mpdd',\t'query',\t'request',\t\t'affect'],\n",
    "                ['del',\t'mpdd',\t'query',\t'request',\t\t'negemo'],\n",
    "                ['del',\t'mpdd',\t'query',\t'request',\t\t'anger'],\n",
    "                ['del',\t'mpdd',\t'res',\t'thanksgiving',\t'affect'],\n",
    "                ['add',\t'cejc',\t'query',\t'apology',\t    'affect'],\n",
    "                ['add',\t'cejc',\t'query',\t'apology',\t    'posemo'],\n",
    "                ['add',\t'cejc',\t'query',\t'apology',\t    'negemo'],\n",
    "                ['add',\t'cejc',\t'query',\t'apology',\t    'anger'],\n",
    "                ['add',\t'cejc',\t'query',\t'request',\t    'negemo'],\n",
    "                ['add',\t'cejc',\t'res',\t'request',\t    'affect'],\n",
    "                ['add',\t'cejc',\t'res',\t'request',\t    'posemo']]\n",
    "# corpus,situation,sentence_type,count_type,unalignment_type,ranking\n",
    "###################################################################\n",
    "###################################################################\n",
    "data = []\n",
    "l_name = []\n",
    "c_name = []\n",
    "s_name = []\n",
    "t_name = []\n",
    "m_name = []\n",
    "d_name = []\n",
    "r_name = []\n",
    "e_name = []\n",
    "for s in sig_list:\n",
    "    unalignment_type=s[0]\n",
    "    corpus=s[1]\n",
    "    sentence_type=s[2]\n",
    "    situation=s[3]\n",
    "    emotion=s[4]\n",
    "\n",
    "    if unalignment_type == 'del':\n",
    "        if corpus == 'cejc':\n",
    "            language = 'jp'\n",
    "        else:\n",
    "            language = 'ch'\n",
    "    else:\n",
    "        if corpus == 'cejc':\n",
    "            language = 'ch'\n",
    "        else:\n",
    "            language = 'jp'\n",
    "\n",
    "    tmp=get_ranking_(corpus,situation,sentence_type,emotion,unalignment_type)\n",
    "    for i in range(6):\n",
    "        l_name.append(f'{language}')\n",
    "        c_name.append(f'{corpus}')\n",
    "        s_name.append(f'{situation}')\n",
    "        t_name.append(f'{sentence_type}')\n",
    "        d_name.append(f'{unalignment_type}')\n",
    "        e_name.append(f'{emotion}')\n",
    "    m_name.extend(['MT','MT','HT','HT','Diff','Diff'])\n",
    "    r_name.extend(['word','freq','word','freq','word','freq'])\n",
    "    data.extend(tmp)\n",
    "    \n",
    "tuples = list(zip(l_name,c_name,s_name,t_name,m_name,d_name,e_name,r_name))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=[\"language\",\"corpus\", \"situation\",\"sentence_type\",\"count_type\",\"unalignment_type\",\"emotion\",\"ranking\",])\n",
    "table = pd.DataFrame(data,index=index)\n",
    "\n",
    "dir_name = 'for_thesis/LIWC_word_ranking/'\n",
    "os.makedirs(dir_name,exist_ok = True) \n",
    "table.to_csv(dir_name+'CLIWC.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unaligned emotion word count and unique count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "table=pd.DataFrame()\n",
    "df = pd.read_csv('CLIWC_diff_reason_table.csv', names=['diff_type','corpus','situation','sen_type','emotion','word','htmt','line','part','effect','direct','intense','perspective'])\n",
    "df = df[df['htmt'].str.contains('HT')]\n",
    "\n",
    "table=df.groupby(['diff_type','corpus','situation','sen_type','emotion'], as_index=False)['word'].count()\n",
    "table=table.rename(columns={'word':'# of words'})\n",
    "\n",
    "df = df.groupby(['diff_type','corpus','situation','sen_type','emotion'], as_index=False)['word'].nunique()\n",
    "table = pd.merge(table,df, on=['diff_type','corpus','situation','sen_type','emotion'])\n",
    "table=table.rename(columns={'word':'# unique of words'})\n",
    "\n",
    "\n",
    "table_=pd.DataFrame()\n",
    "df = pd.read_csv('JIWC_diff_reason_table.csv', names=['diff_type','corpus','situation','sen_type','emotion','word','htmt','line','part','effect','direct','intense','perspective'])\n",
    "df = df[df['htmt'].str.contains('HT')]\n",
    "\n",
    "table_=df.groupby(['diff_type','corpus','situation','sen_type','emotion'], as_index=False)['word'].count()\n",
    "table_=table_.rename(columns={'word':'# of words'})\n",
    "\n",
    "df = df.groupby(['diff_type','corpus','situation','sen_type','emotion'], as_index=False)['word'].nunique()\n",
    "table_ = pd.merge(table_,df, on=['diff_type','corpus','situation','sen_type','emotion'])\n",
    "table_=table_.rename(columns={'word':'# unique of words'})\n",
    "\n",
    "table = pd.concat([table,table_])\n",
    "table = table[['corpus','situation','sen_type','diff_type','emotion','# of words','# unique of words']]\n",
    "table=table.set_axis(['corpus','situation','sentence_type','alignment_type','emotion','# of words','# unique of words'],axis=1)\n",
    "\n",
    "\n",
    "dir_name = 'for_thesis/LIWC_word_ranking/'\n",
    "os.makedirs(dir_name,exist_ok = True) \n",
    "table.to_csv(dir_name+'word_counts.csv',encoding='utf_8_sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
