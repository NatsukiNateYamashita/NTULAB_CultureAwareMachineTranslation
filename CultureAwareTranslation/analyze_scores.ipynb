{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-elephant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conditional-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import sacrebleu\n",
    "# import pyter\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.style\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solar-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "def calc_bert_score(cands, refs):\n",
    "    \"\"\" BERTスコアの算出\n",
    "    Args:\n",
    "        cands ([List[str]]): [比較元の文]\n",
    "        refs ([List[str]]): [比較対象の文]\n",
    "    Returns:\n",
    "        [(List[float], List[float], List[float])]: [(Precision, Recall, F1スコア)]\n",
    "    \"\"\"\n",
    "#     Precision, Recall, F1 = score(cands, refs, lang=\"others\", verbose=True)\n",
    "    Precision, Recall, F1 = score(cands, refs, lang=\"others\", verbose=True, device=1)\n",
    "    Precision = np.mean(Precision.numpy().tolist())\n",
    "    Recall = np.mean(Recall.numpy().tolist())\n",
    "    F1 = np.mean(F1.numpy().tolist())\n",
    "    return Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(hyp,ref):\n",
    "    corpus_bleu = sacrebleu.corpus_bleu(hyp, [ref])\n",
    "    \n",
    "    self_bleu = 0\n",
    "    hyp_ = np.array(hyp)\n",
    "    for idx in range(len(hyp)):\n",
    "        rev_idx = np.arange(len(hyp))\n",
    "        # [True, True, True, True, False, True, False, True, True, True] を作れば良いという方針\n",
    "        bool_idx = np.ones(len(hyp), dtype=bool)\n",
    "        bool_idx[idx] = False\n",
    "        rev_idx = rev_idx[bool_idx]\n",
    "        for rev in rev_idx:\n",
    "            tmp_score = sacrebleu.sentence_bleu(hyp_[idx], [hyp_[rev]])\n",
    "            self_bleu += tmp_score.score\n",
    "    self_bleu /= len(hyp)*(len(hyp)-1)\n",
    "    \n",
    "    ter_scores=[]\n",
    "    for h,r in zip(hyp,ref):\n",
    "        s = pyter.ter(h.split(), r.split())\n",
    "        ter_scores.append(s)\n",
    "    corpus_ter = np.mean(np.array(ter_scores))\n",
    "#     corpus_ter = pyter.ter(hyp,ref)\n",
    "    P, R, F1 = calc_bert_score(hyp, ref)\n",
    "    return [corpus_bleu.score, self_bleu, corpus_ter, P, R, F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_as_list(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf-8-sig')as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            data.append(row[0])\n",
    "    return data\n",
    "\n",
    "def get_df(corpus_list, situation_list, sen_type_list, src_type, context_len, train_type):\n",
    "    target_text = []\n",
    "    input_text = []\n",
    "    prefix = []\n",
    "    for corpus in corpus_list:\n",
    "        for situation in situation_list:\n",
    "            for sen_type in sen_type_list:\n",
    "                f_path = f'/nfs/nas-7.1/yamashita/LAB/dialogue_data/data/{corpus}/{situation}/{context_len}/rewrited_{sen_type}_{train_type}'\n",
    "                target_text += get_data_as_list(f_path)\n",
    "                f_path = f'/nfs/nas-7.1/yamashita/LAB/dialogue_data/data/{corpus}/{situation}/{context_len}/{src_type}_{sen_type}_{train_type}'\n",
    "                input_text += get_data_as_list(f_path)\n",
    "                prefix += [f'{corpus} {situation} {sen_type}']*len(get_data_as_list(f_path))\n",
    "    df = pd.DataFrame([prefix,input_text,target_text], index=['prefix','input_text','target_text']).astype(str).T\n",
    "    return df\n",
    "\n",
    "def get_score_df(path, lang):\n",
    "    path_list = glob.glob(path)\n",
    "    print(path_list)\n",
    "\n",
    "    name_list = []\n",
    "    score_list = []\n",
    "    score_df = pd.DataFrame()\n",
    "    for path in path_list:\n",
    "        name = path.split('/')[2:4]\n",
    "        name_list.append(\"_\".join(name))\n",
    "\n",
    "        df = pd.read_csv(path, index_col=0).astype(str)\n",
    "        preds = df.iloc[:,0].to_list()\n",
    "        truth = df.iloc[:,1].to_list() \n",
    "\n",
    "        score_list.append(get_scores(preds, truth))\n",
    "    \n",
    "    # DEEPL\n",
    "    corpus_list = ['cejc','mpdd']\n",
    "    situation_list = ['apology','request','thanksgiving']\n",
    "    sen_type_list = ['query','res']\n",
    "    context_len = 0\n",
    "    src_type = 'translated' #'translated'\n",
    "    train_type = 'test'  \n",
    "    \n",
    "    eval_df = get_df(corpus_list, situation_list, sen_type_list, src_type, context_len, train_type)\n",
    "    eval_df['input_text']=eval_df['input_text'].str.replace('query: ','')\n",
    "    \n",
    "    if lang=='ja':\n",
    "        _truth = eval_df.loc[eval_df[\"prefix\"].str.contains(\"mpdd\")][\"target_text\"].tolist()\n",
    "        _input = eval_df.loc[eval_df[\"prefix\"].str.contains(\"mpdd\")][\"input_text\"].tolist()\n",
    "    elif lang=='zh':\n",
    "        _truth = eval_df.loc[eval_df[\"prefix\"].str.contains(\"cejc\")][\"target_text\"].tolist()\n",
    "        _input = eval_df.loc[eval_df[\"prefix\"].str.contains(\"cejc\")][\"input_text\"].tolist()\n",
    "    \n",
    "    name_list.append('DeepL')\n",
    "    score_list.append(get_scores(_input,_truth))\n",
    "    \n",
    "    score_df = pd.concat([score_df,pd.DataFrame(score_list, index=name_list, columns=['bleu','selfbleu','ter','bertscore_p','bertscore_r','bertscore_f1'])])\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'outputs/context/'\n",
    "\n",
    "lang = 'ja'\n",
    "path = os.path.join(dir_path, f'*/*/{lang}_preds_truth.csv')\n",
    "\n",
    "ja_score_df = get_score_df(path, lang)\n",
    "\n",
    "lang = 'zh'\n",
    "path = os.path.join(dir_path, f'*/*/{lang}_preds_truth.csv')\n",
    "zh_score_df = get_score_df(path, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_score_df[['ter','bleu','selfbleu','bertscore_f1']].sort_index(ascending=True)\n",
    "zh_score_df[['ter','bleu','selfbleu','bertscore_f1']].sort_index(ascending=True)\n",
    "\n",
    "os.makedirs('for_thesis/generation/scores/',exist_ok=True)\n",
    "ja_score_df.to_csv('for_thesis/generation/scores/ja_score_table.csv',encoding='utf_8_sig')\n",
    "zh_score_df.to_csv('for_thesis/generation/scores/zh_score_table.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_score_df[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "zh_score_df[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-revelation",
   "metadata": {},
   "source": [
    "# Translation x:context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja_score_df[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "ja_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bleu', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(ja_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bleu', ascending=True))\n",
    "zh_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bleu', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(zh_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bleu', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-motorcycle",
   "metadata": {},
   "source": [
    "# Translation x:prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(ja_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))\n",
    "zh_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(zh_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-bailey",
   "metadata": {},
   "source": [
    "# Translation x:prefix relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja_score_df.filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(ja_score_df.filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))\n",
    "# zh_score_df.filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(zh_score_df.filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-david",
   "metadata": {},
   "source": [
    "# StyleTrasnfer x:context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja_score_df[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "ja_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(ja_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))\n",
    "zh_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(zh_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-affect",
   "metadata": {},
   "source": [
    "# StyleTransfer x:prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(ja_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))\n",
    "zh_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(zh_score_df.filter(regex='^(?!.*rel).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-payment",
   "metadata": {},
   "source": [
    "# StyleTransfer x:prefix relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja_score_df.filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bleu', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(ja_score_df.filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))\n",
    "# zh_score_df.filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bleu', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(zh_score_df.filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-triangle",
   "metadata": {},
   "source": [
    "# StyleTransfer input:000_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ja_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(ja_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))\n",
    "# zh_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).plot.bar(rot=70,subplots=True,figsize=(20,6))\n",
    "display(zh_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True))\n",
    "\n",
    "ja_0=ja_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).filter(regex='^([0].*)$', axis=0).mean()\n",
    "ja_3=ja_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).filter(regex='^([3].*)$', axis=0).mean()\n",
    "ja_mean = pd.concat([ja_0,ja_3],axis=1)\n",
    "ja_mean=ja_mean.set_axis(['mt5 TL','mt5 TL+ST'],axis=1)\n",
    "display(ja_mean.T)\n",
    "zh_0=zh_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).filter(regex='^([0].*)$', axis=0).mean()\n",
    "zh_3=zh_score_df.filter(regex='^([0|3].*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].sort_values('bertscore_f1', ascending=True).filter(regex='^([3].*)$', axis=0).mean()\n",
    "zh_mean = pd.concat([zh_0,zh_3],axis=1)\n",
    "zh_mean=zh_mean.set_axis(['mt5 TL','mt5 TL+ST'],axis=1)\n",
    "display(zh_mean.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-groove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ja_score_df[['ter','bleu','selfbleu','bertscore_f1']].corr())\n",
    "display(ja_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].corr())\n",
    "display(ja_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].corr())\n",
    "display(zh_score_df[['ter','bleu','selfbleu','bertscore_f1']].corr())\n",
    "display(zh_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(0.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].corr())\n",
    "display(zh_score_df.filter(regex='^(?!.*prefix).*$', axis=0).filter(regex='^(1.*|DeepL)$', axis=0)[['ter','bleu','selfbleu','bertscore_f1']].corr())\n",
    "\n",
    "ja_score_df[['ter','bleu','selfbleu','bertscore_f1']].corr().to_csv('for_thesis/generation/scores/ja_score_correlation.csv', encoding='utf-8-sig')\n",
    "zh_score_df[['ter','bleu','selfbleu','bertscore_f1']].corr().to_csv('for_thesis/generation/scores/zh_score_correlation.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-foster",
   "metadata": {},
   "source": [
    "# アウトプット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(path,lang):\n",
    "    path_list = glob.glob(path)\n",
    "    print(path_list)\n",
    "\n",
    "    name_list = []\n",
    "    df = pd.DataFrame()\n",
    "    for i,path in enumerate(path_list):\n",
    "        name = path.split('/')[2:4]\n",
    "#         if name[1:3] == situ_and_sentype:\n",
    "        name_list.append(\"_\".join(name))\n",
    "        tmpdf = pd.read_csv(path, index_col=0).astype(str)\n",
    "        if i == 0:\n",
    "            df = tmpdf.drop_duplicates(subset=['truth'])\n",
    "        else:\n",
    "            df = pd.merge(df, tmpdf.drop_duplicates(subset=['truth']), on='truth',how='outer')\n",
    "\n",
    "    corpus_list = ['cejc','mpdd']\n",
    "    situation_list = ['apology','request','thanksgiving']\n",
    "    sen_type_list = ['query','res']\n",
    "    context_len = 0\n",
    "    src_type = 'translated' #'translated'\n",
    "    train_type = 'test'  \n",
    "\n",
    "    eval_df = get_df(corpus_list, situation_list, sen_type_list, src_type, context_len, train_type)\n",
    "    \n",
    "    if lang=='ja':\n",
    "        tmpdf = eval_df.loc[eval_df[\"prefix\"].str.contains(\"mpdd\")]\n",
    "    elif lang=='zh':\n",
    "        tmpdf = eval_df.loc[eval_df[\"prefix\"].str.contains(\"cejc\")]\n",
    "    \n",
    "    name_list.append('DeepL')        \n",
    "    tmpdf.rename(columns={'target_text': 'truth', 'input_text':'DeepL'},inplace=True)\n",
    "    df = pd.merge(df, tmpdf.drop_duplicates(), on='truth',how='outer')\n",
    "    \n",
    "    src_type = 'original' #'translated'\n",
    "    train_type = 'test'  \n",
    "\n",
    "    eval_df = get_df(corpus_list, situation_list, sen_type_list, src_type, context_len, train_type)\n",
    "    \n",
    "    if lang=='ja':\n",
    "        tmpdf = eval_df.loc[eval_df[\"prefix\"].str.contains(\"mpdd\")]\n",
    "    elif lang=='zh':\n",
    "        tmpdf = eval_df.loc[eval_df[\"prefix\"].str.contains(\"cejc\")]\n",
    "    \n",
    "    name_list.append('Original')        \n",
    "    tmpdf.rename(columns={'target_text': 'truth', 'input_text':'Original'},inplace=True)\n",
    "    df = pd.merge(df, tmpdf.drop_duplicates(), on=['truth','prefix'],how='outer')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "dir_path = 'outputs/context/'\n",
    "context_len = 1\n",
    "save_fname = 'all_both'\n",
    "# save_fname = 'all_res'\n",
    "# save_fname = 'apology_all'\n",
    "# save_fname = 'request_all'\n",
    "# save_fname = 'thanksgiving_all'\n",
    "lang = 'ja'\n",
    "path = os.path.join(dir_path, f'*/{context_len}/{lang}_preds_truth.csv')\n",
    "ja_df = get_output(path,lang)\n",
    "# display(ja_df)\n",
    "# print(len(df.drop_duplicates()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'zh'\n",
    "path = os.path.join(dir_path, f'*/{context_len}/{lang}_preds_truth.csv')\n",
    "zh_df = get_output(path,lang)\n",
    "# display(zh_df)\n",
    "# print(len(df.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 400)\n",
    "\n",
    "\n",
    "ja_df[['prefix','Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel','DeepL','truth']].to_excel(dir_path+f'ja_{save_fname}_{context_len}.xlsx')\n",
    "zh_df[['prefix','Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel','DeepL','truth']].to_excel(dir_path+f'zh_{save_fname}_{context_len}.xlsx')\n",
    "# ja_df[['prefix','Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel','300_culturizefromT5train_all_both','300_culturizefromT5train_all_both_prefix','300_culturizefromT5train_all_both_prefix','DeepL','100_culturize_all_both','100_culturize_all_both_prefix','100_culturize_all_both_prefix_rel','truth']].to_excel(dir_path+f'ja_{save_fname}_{context_len}.xlsx')\n",
    "# zh_df[['prefix','Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel','300_culturizefromT5train_all_both','300_culturizefromT5train_all_both_prefix','300_culturizefromT5train_all_both_prefix','DeepL','100_culturize_all_both','100_culturize_all_both_prefix','100_culturize_all_both_prefix_rel','truth']].to_excel(dir_path+f'zh_{save_fname}_{context_len}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_df = ja_df[['prefix','Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel','DeepL','truth']]\n",
    "zh_df = zh_df[['prefix','Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel','DeepL','truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list=['Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel']\n",
    "name_list=[]\n",
    "score_list=[]\n",
    "for column in column_list:\n",
    "    sen_list = ja_df[column].to_list()\n",
    "    truth_list = ja_df['truth'].to_list()\n",
    "    sen_scores=[]\n",
    "    for i,sen in enumerate(sen_list):\n",
    "        sen = str(sen)\n",
    "        sen = sen.replace('query: ','')\n",
    "        _,_,f1 = calc_bert_score([sen], [truth_list[i]])\n",
    "        sen_scores.append(f1)\n",
    "#     _,_,f1 = calc_bert_score(sen_list, truth_list)\n",
    "    score_list.append(sen_scores)\n",
    "    name_list.append(column+' score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_score_df = pd.DataFrame(score_list,index=name_list).T\n",
    "# ja_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list=['Original','000_translate_all_both','000_translate_all_both_prefix','000_translate_all_both_prefix_rel']\n",
    "name_list=[]\n",
    "score_list=[]\n",
    "for column in column_list:\n",
    "    sen_list = zh_df[column].to_list()\n",
    "    truth_list = zh_df['truth'].to_list()\n",
    "    sen_scores=[]\n",
    "    for i,sen in enumerate(sen_list):\n",
    "        sen = sen.replace('query: ','')\n",
    "        _,_,f1 = calc_bert_score([sen], [truth_list[i]])\n",
    "        sen_scores.append(f1)\n",
    "#     _,_,f1 = calc_bert_score(sen_list, truth_list)\n",
    "    score_list.append(sen_scores)\n",
    "    name_list.append(column+' score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_score_df = pd.DataFrame(score_list,index=name_list).T\n",
    "# zh_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_score_df.to_excel(dir_path+f'ja_score_{save_fname}_{context_len}.xlsx')\n",
    "zh_score_df.to_excel(dir_path+f'zh_score_{save_fname}_{context_len}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-scheduling",
   "metadata": {},
   "source": [
    "## for Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "matched-fountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd96764e6f4494f806af732a6331647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c42d9cf8cfa495c992d2a557e5dafe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 0.03 seconds, 33.20 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "hyp = ['お願い。なんでも言ってくれていいから。']\n",
    "ref = ['同級生のためにもお願いします。 何かリクエストがあれば、ぜひ聞いてみてくださいね。']\n",
    "\n",
    "_, _, F1 = calc_bert_score(hyp, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "insured-avatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529513239860535"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "antique-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17cbdb21ce945e4b317d9038af7c807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572bfcbe2a934229802cdc25e60355ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 0.03 seconds, 33.42 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "hyp = ['お願い。なんでも言ってくれていいから。']\n",
    "ref = ['お願いしたいことがあるなら教えてください。']\n",
    "_, _, F1 = calc_bert_score(hyp, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mineral-breakfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81302410364151"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "improving-binding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7b1bbc5f7b4b009a450e5e083ce7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9838c770e744c88bc824e33ecc718a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 0.03 seconds, 35.51 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "hyp = ['お願い。なんでも言ってくれていいから。']\n",
    "ref = ['私にできることなら、なんでもするから言ってよ。お願い。']\n",
    "_, _, F1 = calc_bert_score(hyp, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "direct-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8270285129547119"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ethical-baker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08124fb761b4d4a9a78ce63cef409de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f87606da8348adbe48b07adc1723fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 0.03 seconds, 33.79 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "hyp = ['啊，其實，我也有話想說']\n",
    "ref = ['啊。让我看看。抱歉。我也有。']\n",
    "\n",
    "_, _, F1 = calc_bert_score(hyp, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "antique-wallace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7478231191635132"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "requested-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a85e51701814c37a7ccb8e3077dcd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482a2b6ad5c84538952c134ed462afc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 0.03 seconds, 33.75 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "hyp = ['啊，其實，我也有話想說']\n",
    "ref = ['啊,不好意思']\n",
    "\n",
    "_, _, F1 = calc_bert_score(hyp, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "representative-universe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7479795813560486"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "presidential-implement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecbee61584d41ca8cb8ff6ef1ee8f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f57ab08e164e30a95c7476f9b052f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 0.03 seconds, 35.20 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "hyp = ['啊，其實，我也有話想說']\n",
    "ref = ['啊！我有一個事情想要講']\n",
    "\n",
    "_, _, F1 = calc_bert_score(hyp, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "reasonable-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792472243309021"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-block",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
