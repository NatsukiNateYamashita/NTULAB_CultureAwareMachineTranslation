{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = ['cejc','mpdd']\n",
    "situation_list = ['apology','request','thanksgiving']\n",
    "sen_type_list = ['query','res']\n",
    "src_type = 'original' #'translated'\n",
    "ver_name = '300_culturizefromT5train_all_both'\n",
    "context_len = 0\n",
    "\n",
    "data_ver_name = '000_translate_all_both'\n",
    "\n",
    "data_dir = f'outputs/context/{data_ver_name}/{context_len}/'\n",
    "bestmodel_dir = f'outputs/context/{ver_name}/{context_len}/best_model/'\n",
    "save_dir = f'outputs/context/{ver_name}/{context_len}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_as_list(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf-8-sig')as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            data.append(row[0])\n",
    "    return data\n",
    "\n",
    "def get_df(corpus_list, situation_list, sen_type_list, src_type, context_len, train_type):\n",
    "    target_text = []\n",
    "    input_text = []\n",
    "    prefix = []\n",
    "    for corpus in corpus_list:\n",
    "        for situation in situation_list:\n",
    "            for sen_type in sen_type_list:\n",
    "                f_path = f'/nfs/nas-7.1/yamashita/LAB/dialogue_data/data/{corpus}/{situation}/{context_len}/rewrited_{sen_type}_{train_type}'\n",
    "                target_text += get_data_as_list(f_path)\n",
    "                f_path = f'/nfs/nas-7.1/yamashita/LAB/dialogue_data/data/{corpus}/{situation}/{context_len}/{src_type}_{sen_type}_{train_type}'\n",
    "                input_text += get_data_as_list(f_path)\n",
    "                prefix += [f'{corpus} {situation} {sen_type}']*len(get_data_as_list(f_path))\n",
    "    df = pd.DataFrame([prefix,input_text,target_text], index=['prefix','input_text','target_text']).astype(str).T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sacrebleu\n",
    "import pandas as pd\n",
    "from simpletransformers.t5 import T5Model, T5Args\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "model_args = T5Args()\n",
    "model_args.max_length = 128\n",
    "model_args.length_penalty = 20\n",
    "model_args.num_beams = 10\n",
    "\n",
    "model_ver_name = '000_translate_all_both'\n",
    "bestmodel_dir = f'outputs/context/{model_ver_name}/{context_len}/best_model/'\n",
    "\n",
    "model = T5Model(\"mt5\", bestmodel_dir, args=model_args,cuda_device=1)\n",
    "# model = T5Model(\"mt5\", bestmodel_dir, args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba3015cdb56488795a56f56b2cb36b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=158.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e219119da047fcb4d3467a95adc1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Decoding outputs', max=1262.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64492b403d94a19b411815bc3c1e232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=172.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6cdce2e4d34a3a8d12d55c0f2053be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Decoding outputs', max=1374.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_type = 'train'  \n",
    "train_df = get_df(corpus_list, situation_list, sen_type_list, src_type, context_len, train_type)\n",
    "\n",
    "to_ja_truth = train_df.loc[train_df[\"prefix\"].str.contains(\"mpdd\")][\"target_text\"].tolist()\n",
    "to_ja_input = train_df.loc[train_df[\"prefix\"].str.contains(\"mpdd\")][\"input_text\"].tolist()\n",
    "to_ja_prefix = train_df.loc[train_df[\"prefix\"].str.contains(\"mpdd\")][\"prefix\"].tolist()\n",
    "\n",
    "to_zh_truth = train_df.loc[train_df[\"prefix\"].str.contains(\"cejc\")][\"target_text\"].tolist()\n",
    "to_zh_input = train_df.loc[train_df[\"prefix\"].str.contains(\"cejc\")][\"input_text\"].tolist()\n",
    "to_zh_prefix = train_df.loc[train_df[\"prefix\"].str.contains(\"cejc\")][\"prefix\"].tolist()\n",
    "\n",
    "to_ja_preds = model.predict(to_ja_input)\n",
    "to_zh_preds = model.predict(to_zh_input)\n",
    "\n",
    "input_text = to_ja_preds+to_zh_preds\n",
    "train_df[\"input_text\"] = input_text\n",
    "target_text = to_ja_truth+to_zh_truth\n",
    "train_df[\"target_text\"] = target_text\n",
    "prefix = to_ja_prefix+to_zh_prefix\n",
    "train_df[\"prefix\"] = prefix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f589295547f4437ca367647003e1cb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=20.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859dc4c4d895407aa0ab0fc969384202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Decoding outputs', max=158.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c794bd8e414df480029a49b7698e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=22.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b48257102b4f46a2cc1d164d08fe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Decoding outputs', max=172.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_type = 'val'  \n",
    "eval_df = get_df(corpus_list, situation_list, sen_type_list, src_type, context_len, train_type)\n",
    "\n",
    "to_ja_truth = eval_df.loc[eval_df[\"prefix\"].str.contains(\"mpdd\")][\"target_text\"].tolist()\n",
    "to_ja_input = eval_df.loc[eval_df[\"prefix\"].str.contains(\"mpdd\")][\"input_text\"].tolist()\n",
    "to_ja_prefix = eval_df.loc[eval_df[\"prefix\"].str.contains(\"mpdd\")][\"prefix\"].tolist()\n",
    "\n",
    "to_zh_truth = eval_df.loc[eval_df[\"prefix\"].str.contains(\"cejc\")][\"target_text\"].tolist()\n",
    "to_zh_input = eval_df.loc[eval_df[\"prefix\"].str.contains(\"cejc\")][\"input_text\"].tolist()\n",
    "to_zh_prefix = eval_df.loc[eval_df[\"prefix\"].str.contains(\"cejc\")][\"prefix\"].tolist()\n",
    "\n",
    "to_ja_preds = model.predict(to_ja_input)\n",
    "to_zh_preds = model.predict(to_zh_input)\n",
    "\n",
    "input_text = to_ja_preds+to_zh_preds\n",
    "eval_df[\"input_text\"] = input_text\n",
    "target_text = to_ja_truth+to_zh_truth\n",
    "eval_df[\"target_text\"] = target_text\n",
    "prefix = to_ja_prefix+to_zh_prefix\n",
    "eval_df[\"prefix\"] = prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>ã™ã¿ã¾ã›ã‚“ã€æœ¬å½“ã«é£²ã‚ãªã„ã‚“ã§ã™ã€‚é£²ã‚ã‚‹ãªã‚‰é£²ã‚ãªã„ã‚“ã˜ã‚ƒãªã„ã®?</td>\n",
       "      <td>ã™ã¿ã¾ã›ã‚“ã€‚æœ¬å½“ã«é£²ã‚ãªã„ã‚“ã§ã™ã€‚é£²ã‚ã‚‹ãªã‚‰çµ¶å¯¾ã«é£²ã‚“ã§ã¾ã™ã‚ˆã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>ã™ã¿ã¾ã›ã‚“ã€æœ¬å½“ã«ã”ã‚ã‚“ãªã•ã„ã€‚</td>\n",
       "      <td>ã”ã‚ã‚“ãªã•ã„ã€‚æœ¬å½“ã«ãŠå…„ã•ã‚“ã«ç”³ã—è¨³ãªã„ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>ã™ã¿ã¾ã›ã‚“ã€ä»–ã®ã“ã¨ã¯æ‰¿çŸ¥ã—ã¦ã„ã¾ã™ã€‚ã§ã‚‚ã€ã“ã®å•é¡Œã¯å—ã‘å…¥ã‚Œã‚‰ã‚Œãªã„ã‚“ã§ã™ã€‚</td>\n",
       "      <td>ã”ã‚ã‚“ã€ä»–ã®ã“ã¨ã¯ã¨ã‚‚ã‹ãã€ã“ã‚Œã ã‘ã¯ã ã‚ãªã‚“ã ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>ã”ã‚ã‚“ã€å…„ã‚’æ”¾ã—ã¦ã‚ã’ã¦ãã‚Œãªã„?</td>\n",
       "      <td>ã”ã‚ã‚“ã€‚å…„ã‚’æ”¾ã—ã¦ã‚ã’ã¦ãã‚Œãªã„ï¼Ÿ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>ãã‚“ãªã“ã¨è¨€ã†ãªã‚ˆã€‚ç”³ã—è¨³ãªã„ã€‚</td>\n",
       "      <td>ã‚„ã‚ã¦ã‚ˆã€‚æ‚ªã„ã®ã¯åŠ©ã‘ã‚‰ã‚Œãªã„ç§ã ã‹ã‚‰ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prefix                               input_text  \\\n",
       "0               ã™ã¿ã¾ã›ã‚“ã€æœ¬å½“ã«é£²ã‚ãªã„ã‚“ã§ã™ã€‚é£²ã‚ã‚‹ãªã‚‰é£²ã‚ãªã„ã‚“ã˜ã‚ƒãªã„ã®?   \n",
       "1                                ã™ã¿ã¾ã›ã‚“ã€æœ¬å½“ã«ã”ã‚ã‚“ãªã•ã„ã€‚   \n",
       "2         ã™ã¿ã¾ã›ã‚“ã€ä»–ã®ã“ã¨ã¯æ‰¿çŸ¥ã—ã¦ã„ã¾ã™ã€‚ã§ã‚‚ã€ã“ã®å•é¡Œã¯å—ã‘å…¥ã‚Œã‚‰ã‚Œãªã„ã‚“ã§ã™ã€‚   \n",
       "3                               ã”ã‚ã‚“ã€å…„ã‚’æ”¾ã—ã¦ã‚ã’ã¦ãã‚Œãªã„?   \n",
       "4                                ãã‚“ãªã“ã¨è¨€ã†ãªã‚ˆã€‚ç”³ã—è¨³ãªã„ã€‚   \n",
       "\n",
       "                        target_text  \n",
       "0  ã™ã¿ã¾ã›ã‚“ã€‚æœ¬å½“ã«é£²ã‚ãªã„ã‚“ã§ã™ã€‚é£²ã‚ã‚‹ãªã‚‰çµ¶å¯¾ã«é£²ã‚“ã§ã¾ã™ã‚ˆã€‚  \n",
       "1             ã”ã‚ã‚“ãªã•ã„ã€‚æœ¬å½“ã«ãŠå…„ã•ã‚“ã«ç”³ã—è¨³ãªã„ã€‚  \n",
       "2         ã”ã‚ã‚“ã€ä»–ã®ã“ã¨ã¯ã¨ã‚‚ã‹ãã€ã“ã‚Œã ã‘ã¯ã ã‚ãªã‚“ã ã€‚  \n",
       "3                 ã”ã‚ã‚“ã€‚å…„ã‚’æ”¾ã—ã¦ã‚ã’ã¦ãã‚Œãªã„ï¼Ÿ  \n",
       "4              ã‚„ã‚ã¦ã‚ˆã€‚æ‚ªã„ã®ã¯åŠ©ã‘ã‚‰ã‚Œãªã„ç§ã ã‹ã‚‰ã€‚  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>ã”ã‚ã‚“ãªã•ã„ã€ã‚ã–ã¨ã˜ã‚ƒãªã„ã‚“ã ã€‚</td>\n",
       "      <td>ã”ã‚ã‚“ã­ã€ãã‚“ãªã¤ã‚‚ã‚Šã˜ã‚ƒãªã‹ã£ãŸã‚“ã ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>æ˜¨æ—¥å‡ºã‹ã‘ã¾ã—ãŸã€‚ã¡ã‚‡ã£ã¨é…ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸã€‚</td>\n",
       "      <td>ä»Šæ—¥å‡ºã¦ããŸã°ã‹ã‚Šãªã®ã«ã€ã¾ãŸæˆ»ã‚‹ãªã‚“ã¦ã€æœ¬å½“ã«ç”³ã—è¨³ãªã„ã§ã™ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>ã™ã¿ã¾ã›ã‚“ã€å››è¬å…ƒã‚’ãã‚ŒãŸã‚“ã§ã™ã€‚</td>\n",
       "      <td>ã™ã¿ã¾ã›ã‚“ã€å››ä¸‡å…ƒæŒã£ã¦ãã¾ã—ãŸã‚“ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>ã”ã‚ã‚“ã­ã€‚ã§ã‚‚ã€ç§ã«ã¯é–¢ä¿‚ãªã„ã‘ã©ã€ã©ã£ã¡ã§ã‚‚ã„ã„ã˜ã‚ƒã‚“ã€‚</td>\n",
       "      <td>è¬ã‚‹ã®ã¯ç§ã®æ–¹ã ã‚ˆã€‚ãã†ã„ã†é¢¨ã«æ€ã‚ã¦ã‚‹ã£ã¦çŸ¥ã£ã¦ãŸã‚“ã ã‹ã‚‰ã€‚ã§ã‚‚ã€ãã†ã„ã†ã®ã¯äºŒäººã®ã“ã¨ã ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>ã”ã‚ã‚“ãªã•ã„ã€åŠ©ã‘ã¦ã‚‚ã‚‰ãˆã¾ã›ã‚“ã€‚</td>\n",
       "      <td>ãã‚Œã¯åŠ›ã«ãªã‚Œãªã„ã€‚ã”ã‚ã‚“ã­ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prefix                     input_text  \\\n",
       "0                     ã”ã‚ã‚“ãªã•ã„ã€ã‚ã–ã¨ã˜ã‚ƒãªã„ã‚“ã ã€‚   \n",
       "1               æ˜¨æ—¥å‡ºã‹ã‘ã¾ã—ãŸã€‚ã¡ã‚‡ã£ã¨é…ã‚Œã¦ã—ã¾ã„ã¾ã—ãŸã€‚   \n",
       "2                     ã™ã¿ã¾ã›ã‚“ã€å››è¬å…ƒã‚’ãã‚ŒãŸã‚“ã§ã™ã€‚   \n",
       "3         ã”ã‚ã‚“ã­ã€‚ã§ã‚‚ã€ç§ã«ã¯é–¢ä¿‚ãªã„ã‘ã©ã€ã©ã£ã¡ã§ã‚‚ã„ã„ã˜ã‚ƒã‚“ã€‚   \n",
       "4                     ã”ã‚ã‚“ãªã•ã„ã€åŠ©ã‘ã¦ã‚‚ã‚‰ãˆã¾ã›ã‚“ã€‚   \n",
       "\n",
       "                                         target_text  \n",
       "0                               ã”ã‚ã‚“ã­ã€ãã‚“ãªã¤ã‚‚ã‚Šã˜ã‚ƒãªã‹ã£ãŸã‚“ã ã€‚  \n",
       "1                   ä»Šæ—¥å‡ºã¦ããŸã°ã‹ã‚Šãªã®ã«ã€ã¾ãŸæˆ»ã‚‹ãªã‚“ã¦ã€æœ¬å½“ã«ç”³ã—è¨³ãªã„ã§ã™ã€‚  \n",
       "2                                 ã™ã¿ã¾ã›ã‚“ã€å››ä¸‡å…ƒæŒã£ã¦ãã¾ã—ãŸã‚“ã€‚  \n",
       "3  è¬ã‚‹ã®ã¯ç§ã®æ–¹ã ã‚ˆã€‚ãã†ã„ã†é¢¨ã«æ€ã‚ã¦ã‚‹ã£ã¦çŸ¥ã£ã¦ãŸã‚“ã ã‹ã‚‰ã€‚ã§ã‚‚ã€ãã†ã„ã†ã®ã¯äºŒäººã®ã“ã¨ã ...  \n",
       "4                                    ãã‚Œã¯åŠ›ã«ãªã‚Œãªã„ã€‚ã”ã‚ã‚“ã­ã€‚  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"prefix\"] = \"\"\n",
    "eval_df[\"prefix\"] = \"\"\n",
    "\n",
    "display(train_df.iloc[:5])\n",
    "display(eval_df.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4e911bd0b84143ae28c81e5f8c5c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2636.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.t5.t5_model: Training started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Adafactor for T5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d4f13c6f594944b75ff6b48126f1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=20.0, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnatsukinateyamashita\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">electric-fire-20</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/natsukinateyamashita/300_culturizefromT5train_all_both\" target=\"_blank\">https://wandb.ai/natsukinateyamashita/300_culturizefromT5train_all_both</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/natsukinateyamashita/300_culturizefromT5train_all_both/runs/hjom9m81\" target=\"_blank\">https://wandb.ai/natsukinateyamashita/300_culturizefromT5train_all_both/runs/hjom9m81</a><br/>\n",
       "                Run data is saved locally in <code>/nfs/nas-7.1/yamashita/LAB/SimpleTransformer/wandb/run-20210716_003255-hjom9m81</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d6bc7198e5425b8d2607bfc49b2831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/optimization.py:557: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
      "  exp_avg_sq_row.mul_(beta2t).add_(1.0 - beta2t, update.mean(dim=-1))\n",
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73e578c4e0d46778b59aa69649859c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.t5.t5_model: Current step: 1\n",
      "INFO:simpletransformers.t5.t5_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed90a31f61d44dab5e9d2c98bb0a362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668936c418924faf86d5c9a813c214f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfdcf3dd0bc43619e306a48cd0ce1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dd2c10e8424788abcd11bd8864cc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418a3d7d24ac41bfbfb0428a5aa708a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0656041d06e84f409ab5a2cc5265ff76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc30477dd0504654a9776de689454961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77b89d2fddb4c12a38f5a8164520421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f236c9dc96e84b0db7f8cba1d78a4ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a1af56408e42989b520f4b5a64914a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8418d314c8b947c8a253a984ceb30d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258d166bd8784c0ea3b1ac1d43ed5947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 3 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e9a8c08f7344ce836210d08a563d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd4b225d3fc4fbbb6717a90dfcc0925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92b9564fcc34d88bd06af599e149e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7775ec61d6e4fb6934825e801db1891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b409c86e15e4ebf93c9478c75633393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 4 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de77b95af7641f9b0c81a65e2fd94f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab59937cde54e99905d0aee43ae200f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f315f092be4fa2bf9c00b0bfc45e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2b39ac3766474e89628b689c93991e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75243bf9b0a41aeb583424d93b870a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 5 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ea48891d94354a039f11f23e87838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.t5.t5_model: Current step: 1\n",
      "INFO:simpletransformers.t5.t5_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bcdc43ead84d32a87df387ac0d1eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106cbd5be21c409fae85a61aa9b36f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cda3a9175a84bb1893a024aea7bab95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 6 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98869811bf5545abb2ca0400f21ffa68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.t5.t5_model: Current step: 1\n",
      "INFO:simpletransformers.t5.t5_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1442096d7c594018ac30d3b42d425352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.t5.t5_model: Current step: 2\n",
      "INFO:simpletransformers.t5.t5_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164bb4ed9b5948fa92fcc6b6f98f19fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.t5.t5_model: Current step: 3\n",
      "INFO:simpletransformers.t5.t5_model: Early stopping patience: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3b02fd4e0748fc9f0b54bee8a960f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1617ab5af7b143d99d83c83d62406060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 7 of 20', max=1318.0, style=ProgressStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1264cdddb14a508dcec708b8c827f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: Patience of 3 steps reached\n",
      "INFO:simpletransformers.t5.t5_model: Training terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.t5.t5_model: Training of google/mt5-base model complete. Saved to outputs/context/300_culturizefromT5train_all_both/0/ckpt/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9500,\n",
       " {'global_step': [500,\n",
       "   1000,\n",
       "   1318,\n",
       "   1500,\n",
       "   2000,\n",
       "   2500,\n",
       "   2636,\n",
       "   3000,\n",
       "   3500,\n",
       "   3954,\n",
       "   4000,\n",
       "   4500,\n",
       "   5000,\n",
       "   5272,\n",
       "   5500,\n",
       "   6000,\n",
       "   6500,\n",
       "   6590,\n",
       "   7000,\n",
       "   7500,\n",
       "   7908,\n",
       "   8000,\n",
       "   8500,\n",
       "   9000,\n",
       "   9226,\n",
       "   9500],\n",
       "  'eval_loss': [10.239910767295143,\n",
       "   5.71810031226187,\n",
       "   4.85611592206088,\n",
       "   4.4295251940235945,\n",
       "   3.966494723883542,\n",
       "   3.621848180438533,\n",
       "   3.5723213779203817,\n",
       "   3.4983110899275,\n",
       "   3.380092240824844,\n",
       "   3.292085610510725,\n",
       "   3.290008735340653,\n",
       "   3.2256622273362043,\n",
       "   3.1887129399361034,\n",
       "   3.192090814221989,\n",
       "   3.1859081103946223,\n",
       "   3.16193455642823,\n",
       "   3.1497862697099195,\n",
       "   3.1507292314460784,\n",
       "   3.1548830702449338,\n",
       "   3.1104407728621455,\n",
       "   3.124794711985371,\n",
       "   3.1201769626953384,\n",
       "   3.117850523780693,\n",
       "   3.1287690742900875,\n",
       "   3.1238782767093545,\n",
       "   3.1130690496979336],\n",
       "  'train_loss': [10.37309455871582,\n",
       "   13.879570960998535,\n",
       "   6.392226696014404,\n",
       "   7.174092769622803,\n",
       "   7.25306510925293,\n",
       "   3.1848948001861572,\n",
       "   4.30210542678833,\n",
       "   5.69883918762207,\n",
       "   4.761964321136475,\n",
       "   5.202020645141602,\n",
       "   3.0497405529022217,\n",
       "   5.047584056854248,\n",
       "   3.4359912872314453,\n",
       "   5.399889945983887,\n",
       "   4.895778656005859,\n",
       "   1.0959603786468506,\n",
       "   3.6643455028533936,\n",
       "   0.9875140190124512,\n",
       "   5.0149688720703125,\n",
       "   3.258178472518921,\n",
       "   0.817335307598114,\n",
       "   3.9878885746002197,\n",
       "   1.2458807229995728,\n",
       "   4.087122440338135,\n",
       "   3.7261006832122803,\n",
       "   4.431268692016602]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = T5Args()\n",
    "\n",
    "model_args.max_seq_length = 128\n",
    "model_args.length_penalty = 20\n",
    "model_args.train_batch_size = 2\n",
    "model_args.eval_batch_size = 2\n",
    "model_args.num_train_epochs = 20\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_steps = 500\n",
    "model_args.use_multiprocessing = False\n",
    "model_args.fp16 = False\n",
    "model_args.early_stopping_metric = 'eval_loss'\n",
    "model_args.early_stopping_metric_minimize = True\n",
    "model_args.early_stopping_patience = 3\n",
    "model_args.use_early_stopping = True\n",
    "model_args.save_eval_checkpoints = True\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.learning_rate = 3e-5\n",
    "model_args.best_model_dir = save_dir+'best_model/'\n",
    "model_args.output_dir = save_dir+'ckpt/'\n",
    "model_args.save_model_every_epoch = True\n",
    "model_args.save_steps = -1\n",
    "model_args.no_cache = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.preprocess_inputs = False\n",
    "model_args.num_return_sequences = 1\n",
    "model_args.wandb_project = ver_name\n",
    "\n",
    "model = T5Model(\"mt5\", \"google/mt5-base\", args=model_args, cuda_device=1)\n",
    "# model = T5Model(\"mt5\", \"google/mt5-base\", args=model_args)\n",
    "# Train the model\n",
    "os.environ['WANDB_CONSOLE'] = 'off'\n",
    "model.train_model(train_df, eval_data=eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sacrebleu\n",
    "import pandas as pd\n",
    "from simpletransformers.t5 import T5Model, T5Args\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "model_args = T5Args()\n",
    "model_args.max_length = 128\n",
    "model_args.length_penalty = 20\n",
    "model_args.num_beams = 10\n",
    "\n",
    "model = T5Model(\"mt5\", save_dir+\"best_model/\", args=model_args, cuda_device=1)\n",
    "# model = T5Model(\"mt5\", save_dir+\"best_model/\", args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[': ä»Šæ—¥ã®å½±éŸ¿ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã™ã¿ã¾ã›ã‚“ã€‚',\n",
       " ': ä»Šæ›´å‚·ã¤ã„ãŸã‚ˆã€‚ãŸã ã€ç§ã‚’ç…§é¡§ã—ã¦ãã‚Œãªã„?',\n",
       " ': ã”ã‚ã‚“ã­ã€æœ¬ã¯èª­ã¾ãªã„ã‚“ã§ã™ã€‚',\n",
       " ': ã”ã‚ã‚“ã€å…ˆæ‰•ã„ãªã•ã„ã€‚å¿ƒãŒç–²ã‚Œã¦ã‚‹ã‹ã‚‰ã€‚',\n",
       " ': ã”ã‚ã‚“ã€é…ã‚Œã¦ã”ã‚ã‚“ã€‚']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ja_eval_df = pd.read_csv(f\"{data_dir}ja_preds_truth.csv\").astype(str)\n",
    "zh_eval_df = pd.read_csv(f\"{data_dir}zh_preds_truth.csv\").astype(str)\n",
    "\n",
    "to_ja_truth = ja_eval_df[\"truth\"].tolist()\n",
    "to_ja_input = ja_eval_df[f\"{data_ver_name}\"].tolist()\n",
    "\n",
    "to_zh_truth = zh_eval_df[\"truth\"].tolist()\n",
    "to_zh_input = zh_eval_df[f\"{data_ver_name}\"].tolist()\n",
    "\n",
    "to_ja_input = [\": \" + input_text for input_text in to_ja_input]\n",
    "to_zh_input = [\": \" + input_text for input_text in to_zh_input]\n",
    "\n",
    "to_ja_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5adb31d19740bd80065a79e6cedf41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=20.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamashita/anaconda3/envs/st/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defacf2dace64b0fba4334a77de94781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Decoding outputs', max=160.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca8628b6e2c4aa6ac998118f32283ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=22.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b278129f03495082a3f7d7ad3301f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Decoding outputs', max=174.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "to_ja_preds = model.predict(to_ja_input)\n",
    "to_zh_preds = model.predict(to_zh_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ja_df = pd.DataFrame([to_ja_preds,to_ja_truth],index=[f'{ver_name}', 'truth'])\n",
    "r_ja_df.T.to_csv(save_dir+'ja_preds_truth.csv',encoding='utf_8_sig')\n",
    "\n",
    "r_zh_df = pd.DataFrame([to_zh_preds,to_zh_truth],index=[f'{ver_name}', 'truth'])\n",
    "r_zh_df.T.to_csv(save_dir+'zh_preds_truth.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
